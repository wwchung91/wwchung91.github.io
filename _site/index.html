<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Wally WonTaek Chung's CV</title>

  <!-- Google font typography settings - defined in _config.yml -->
  
  <link href='https://fonts.googleapis.com/css?family=Lora:400,700|Open+Sans:400,300,800,700' rel='stylesheet' type='text/css'>
  

  <meta name="description" content="A resume template for Jekyll and GitHub Pages sites.">

  <link rel="stylesheet" href="css/main.css">
  <link rel="canonical" href="http://localhost:4000/">
  <link rel="icon" type="image/x-icon" href="/favicon.png" />
</head>


  <body class="theme-default">

    <div class="wrapper" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="telephone" content="+8210-3805-5721"/>
      <meta itemprop="address" content="Seoul, South Korea"/>

      <header class="page-header">

        <!-- You can turn off the avatar in _config.yml by setting to false -->
        
        <img src="images/avatar.jpg" alt="my photo" class="avatar no-print" itemprop="image">
        

        <!-- Your name is defined in the _config.yml file -->
        <h1 class="header-name" itemprop="name">Wally WonTaek Chung</h1>

        <!-- To display contact info here, change `display_header_contact_info` value in _config.yml to true -->
        
        <div class="header-contact-info">
          <p>Seoul, South Korea • +8210-3805-5721 • wwchung91@gmail.com</p>
        </div>
        

        <div class="title-bar no-print">

          <!-- Your title is also defined in the _config.yml file -->
          <h2 class="header-title" itemprop="jobTitle">Project Manager/Software Engineer</h2>

          <!-- This is the markup for the icon links; moved out to an include because it's very verbose, and you shouldn't ever need to edit the markup (unless you want to re-order the icons); if you want to customize which links appear, define them in the _config.yml file -->
          <!-- and guess where these are defined? Yup, you guessed it: the _config.yml file -->

<ul class="icon-links">

  <!-- GitHub link -->
  

  <!-- Twitter link -->
  
  <li class="icon-link-item"><a href="http://twitter.com/chung_wally" class="icon-link" itemprop="sameAs"><svg class="icon" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px"
   viewBox="0 0 28 28" enable-background="new 0 0 28 28" xml:space="preserve" width="28">
<path id="Twitter" fill="#D1CECC" d="M14,0C6.27,0,0,6.27,0,14s6.27,14,14,14s14-6.27,14-14S21.73,0,14,0z M20.69,10.57
  c0.01,0.15,0.01,0.3,0.01,0.45c0,4.56-3.47,9.82-9.82,9.82c-1.95,0-3.76-0.57-5.29-1.55c0.27,0.03,0.54,0.05,0.82,0.05
  c1.62,0,3.11-0.55,4.29-1.48c-1.51-0.03-2.79-1.03-3.23-2.4c0.21,0.04,0.43,0.06,0.65,0.06c0.31,0,0.62-0.04,0.91-0.12
  c-1.58-0.32-2.77-1.71-2.77-3.39c0-0.01,0-0.03,0-0.04c0.47,0.26,1,0.41,1.56,0.43c-0.93-0.62-1.54-1.68-1.54-2.87
  c0-0.63,0.17-1.23,0.47-1.74c1.7,2.09,4.25,3.46,7.12,3.61c-0.06-0.25-0.09-0.52-0.09-0.79c0-1.91,1.55-3.45,3.45-3.45
  c0.99,0,1.89,0.42,2.52,1.09c0.79-0.15,1.53-0.44,2.19-0.84c-0.26,0.81-0.81,1.48-1.52,1.91c0.7-0.08,1.36-0.27,1.98-0.54
  C21.95,9.47,21.37,10.08,20.69,10.57z"/>
</svg>
</a></li>
  
  
  <!-- Medium link -->
  

  <!-- Dribbble link -->
  

  <!-- Facebook link -->
  

  <!-- LinkedIn link -->
  
  <li class="icon-link-item"><a href="https://www.linkedin.com/in/wally-wontaek-chung-60903aa2/" class="icon-link" itemprop="sameAs"><svg class="icon" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px"
   viewBox="0 0 28 28" enable-background="new 0 0 28 28" xml:space="preserve" width="28">
<path id="LinkedIn" fill="#D1CECC" d="M18.82,15.09v3.61h-2.09v-3.37c0-0.85-0.3-1.42-1.06-1.42c-0.58,0-0.92,0.39-1.07,0.77
  c-0.06,0.13-0.07,0.32-0.07,0.51v3.52h-2.09c0,0,0.03-5.71,0-6.3h2.09v0.89c0,0.01-0.01,0.01-0.01,0.02h0.01V13.3
  c0.28-0.43,0.77-1.04,1.89-1.04C17.79,12.25,18.82,13.16,18.82,15.09z M9.18,18.7h2.09v-6.3H9.18V18.7z M10.24,9.36
  c-0.72,0-1.19,0.47-1.19,1.09c0,0.61,0.45,1.09,1.16,1.09h0.01c0.73,0,1.18-0.48,1.18-1.09C11.39,9.84,10.95,9.36,10.24,9.36z
   M28,14c0,7.73-6.27,14-14,14S0,21.73,0,14S6.27,0,14,0S28,6.27,28,14z M20.93,8.02c0-0.55-0.46-1-1.02-1H8.09
  c-0.57,0-1.02,0.45-1.02,1v11.96c0,0.55,0.46,1,1.02,1h11.82c0.57,0,1.02-0.45,1.02-1V8.02z"/>
</svg>
</a></li>
  

  <!-- Instagram link -->
  

  <!-- Website link -->
  

</ul>


        </div>

        <div class="executive-summary" itemprop="description">
          <p><strong>Professional Objective</strong> - Dedicated AI researcher with a passion for pushing the boundaries of artificial intelligence to solve complex problems. My interest lies in the field of <strong>Artificial Intelligence</strong>, <strong>Computer Vision</strong>, <strong>Deep Learning</strong>, <strong>Machine Learning</strong>, and <strong>Robotics</strong>. </p>
        </div>

        
        <a href="mailto:wwchung91@gmail.com" class="contact-button no-print" itemprop="email">Contact me</a>
        

      </header>
      
      <!-- begin Education -->
      <section class="content-section">
        <header class="section-header">
          <h2>Education</h2>
        </header>

        
        <div class="resume-item" itemscope itemprop="alumniOf" itemtype="http://schema.org/CollegeOrUniversity">
          <h3 class="resume-item-title" itemprop="name">Pohang University of Science and Technology, Republic of Korea</h3>
          <h4 class="resume-item-details group" itemprop="description">MS in Computer Science with 3.70 GPA &bull; 2016</h4>
          <h5 class="resume-item-details award-title" itemprop="description"></h5>
          <p class="resume-item-copy" itemprop="description">
            <ul class="resume-item-list">
              
            </ul></h5>


          <p class="resume-item-copy">Thesis titled "Moving object detection under an non-stationary camera using a improved background model with foreground clues". Focused on Computer Vision, Machine Learning, Pattern Recognition.</p>
        </div>
        
        <div class="resume-item" itemscope itemprop="alumniOf" itemtype="http://schema.org/CollegeOrUniversity">
          <h3 class="resume-item-title" itemprop="name">Georgia Institute of Technology, USA</h3>
          <h4 class="resume-item-details group" itemprop="description">BS in Computer Science with 3.05 GPA &bull; 2014</h4>
          <h5 class="resume-item-details award-title" itemprop="description"></h5>
          <p class="resume-item-copy" itemprop="description">
            <ul class="resume-item-list">
              
            </ul></h5>


          <p class="resume-item-copy">Threads in Intelligence and Information Internetwork</p>
        </div>
        
      </section>
      <!-- end Education -->
      

      
      <!-- begin Experience -->
      <section class="content-section">

        <header class="section-header">
          <h2>Work Experience</h2>
        </header>

        
        <div class="resume-item" itemscope itemprop="worksFor" itemtype="http://schema.org/Organization">
          <h3 class="resume-item-title" itemprop="name">AIBrain Asia & Crosscert</h3>
          <h4 class="resume-item-details" itemprop="description">Product Manager/Software Engineer &bull; Present &mdash; 2016</h4>
          <p class="resume-item-copy">Managed and developed robotics products that include computer vision, machine learning, and conversational AI. Mainly focused on creating an open-sourced humanoid platform.</p><br>
          <!--ul class="resume-item-list"-->
            
            <h4 class="resume-item-details" itemprop="description">Gretchen Humanoid Robot Head with a 2D Camera </h4>
            <p class="resume-item-copy"><strong> [Developer] </strong> Created an open-source robot head research platform with a 2D camera. Developed a hardware framework with 3D printing and ROBOTIS motors. Developed a software framework with ROS to control the motor, estimate the positions of objects in robot coordinates system, and remotely control the robot. The motivation of creating the Gretchen Humanoid Robot Head with a 2D camera was to provide an easy to assemble and affordable solution for students. This Gretchen Humanoid Robot Head was mainly used for SNU's international summer program.</p>
            <p class="resume-item-copy"><strong> [Required Skillset] </strong> ROS, C++, Python, Fusion360, Cura</p>
            <p class="resume-item-copy"><img width="350" height="250" src="images/gretchen-head-2d.png" alt="my photo" class="avatar no-print" itemprop="image"> <img width="350" height="250" src="images/gretchen-2d-architecture.png" alt="my photo" class="avatar no-print" itemprop="image"> <iframe width="350" height="250" src="https://www.youtube.com/embed/9-S6prOuEXU?si=TTUjKCkRzi5tyTqo" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe></p><br>
            
            <h4 class="resume-item-details" itemprop="description">Gretchen Humanoid Robot Head with a 3D Camera </h4>
            <p class="resume-item-copy"><strong> [Developer] </strong> Created an open-source robot head research platform with a 3D camera. Developed a software framework with ROS to control the motor, estimate headpose, detect objects, and estimate the position of the objects in robot coordinates system. The Gretchen Humanoid Robot Head was intended to support AIBrain's conversational AI by implementing social gaze. The robot gathers environmental knowledge by creating a map of the objects in the environment. It estimates the gaze direction of the user and does a simple analysis of the conversation to determine head motion behavior.</p>
            <p class="resume-item-copy"><strong> [Required Skillset] </strong> ROS, C++, Python, Fusion360, Cura</p>
            <p class="resume-item-copy"><img width="350" height="247" src="images/gretchen-head-3d.png" alt="my photo" class="avatar no-print" itemprop="image"> <img width="350" height="250" src="images/gretchen-head-3d-social-gaze.png" alt="my photo" class="avatar no-print" itemprop="image"> <iframe width="350" height="250" src="https://www.youtube.com/embed/l9jIMoOXDGQ?si=77-xhdG7anlJXjAR" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe></p><br>
            
            <h4 class="resume-item-details" itemprop="description">Gretchen Humanoid AI Online Course </h4>
            <p class="resume-item-copy"><strong> [Instructor] </strong> Based on the Gretchen Humanoid Robot Head with a 2D Camera, we created a 9 week online course that works as a guide for using the open sourced platform. The course contains lecture, hands-on experience, and homework. After the course, students should be able to program a functional robot head.</p>
            <p class="resume-item-copy"><strong> [Required Skillset] </strong> ROS, C++, Python, Moodle</p>
            <p class="resume-item-copy"><img width="350" height="250" src="images/gretchen-online-course.png" alt="my photo" class="avatar no-print" itemprop="image"> <img width="350" height="250" src="images/gretchen-online-course-sessions.png" alt="my photo" class="avatar no-print" itemprop="image"> <iframe width="350" height="250" src="https://www.youtube.com/embed/R0SX7h5h7bY?si=ncb9OROu9MF7SpV8" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe></p><br>
            
            <h4 class="resume-item-details" itemprop="description">Gretchen Humanoid Robot Leg </h4>
            <p class="resume-item-copy"><strong> [Developer] </strong> Working on an open-source robot leg research platform to experiment walking and balancing algorithms. The hardware was initially created by Humboldt-Universität zu Berlin. The hardware itself needed more improvements and iterations. Software development also more substantial effort and resources.</p>
            <p class="resume-item-copy"><strong> [Required Skillset] </strong> ROS, C++, Python, Fusion360, Cura, Gazebo, Pybullet, Pytorch</p>
            <p class="resume-item-copy"><img width="260" height="250" src="images/gretchen-leg-v1.jpg" alt="my photo" class="avatar no-print" itemprop="image"> <iframe width="260" height="250" src="https://www.youtube.com/embed/ssVAxvMDQzs?si=PP_NfbyE9RUp3lbn" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe> <img width="260" height="250" src="images/gretchen-leg-v2.png" alt="my photo" class="avatar no-print" itemprop="image"> <iframe width="260" height="250" src="https://www.youtube.com/embed/UEJbYHxV1Uw?si=_hLpWqZV7eHktPRo" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe></p><br>
            
            <h4 class="resume-item-details" itemprop="description">Quattro Mini Robot </h4>
            <p class="resume-item-copy"><strong> [Team Member] </strong> Quattro is a mini robot that is used to introduce children to robotics. Students have to build legs and adjust the gait pattern to make the robot walk. After making the robot walk, students have to teach the robot to stop when there is an obstacle in front of the robot. We implemented this feature with q-learning so that students can get an idea of reinforcement learning in robotics.</p>
            <p class="resume-item-copy"><strong> [Required Skillset] </strong> Arduino</p>
            <p class="resume-item-copy"><iframe width="350" height="250" src="https://www.youtube.com/embed/W1IbPd5jvEI?si=dN5cy4N9QURzCwoC" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe> <img width="350" height="230" src="images/quattro-rl.png" alt="my photo" class="avatar no-print" itemprop="image">  <iframe width="350" height="250" src="https://www.youtube.com/embed/aRbtsG59ipI?si=yrR2KLxNzdAfggS_" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe></p><br>
            
            <h4 class="resume-item-details" itemprop="description">Athena Personal Assistant Robot </h4>
            <p class="resume-item-copy"><strong> [Project Manager] </strong> Managed the development of a SLAM based personal assistant. The turtlebot used lidar and a RGBD camera to map the indoor environment. Then, global and local path was created to determine which route the robot should take to reach the goal position.</p>
            <p class="resume-item-copy"></p>
            <p class="resume-item-copy"><img width="350" height="250" src="images/athena-hardware.png" alt="my photo" class="avatar no-print" itemprop="image">  <img width="350" height="250" src="images/athena-hardware-inside.png" alt="my photo" class="avatar no-print" itemprop="image">  <iframe width="350" height="250" src="https://www.youtube.com/embed/FTnMlzWFFTA?si=mx8NzHdqe7ZqG7K0" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe></p><br>
            
            <h4 class="resume-item-details" itemprop="description">Sensoriboard/Sensorimotor </h4>
            <p class="resume-item-copy"><strong> [Team Member] </strong> Sensoriboard is a board that is connected to a motor and allows motor control to be customized. The main aim of the sensoriboard is to reduce the cost of servo motors while also making the motors fully customizable. Assuming the sensoriboards were mass produced, the price is reduced significantly. The problem of sensoriboards were that everything had to be developed from scratch making it very hard to use and prone to inaccurate motor movement. Initially, the sensoriboards/sensorimotors were used in the Gretchen robot.</p>
            <p class="resume-item-copy"></p>
            <p class="resume-item-copy"><img width="350" height="247" src="images/sensorimotor.jpg" alt="my photo" class="avatar no-print" itemprop="image"> <img width="350" height="247" src="images/sensoriboard-cam.png" alt="my photo" class="avatar no-print" itemprop="image"></p><br>
            
          <!--</ul></h5>-->

          <p class="resume-item-copy">
        </div><!-- end of resume-item -->
        
        <div class="resume-item" itemscope itemprop="worksFor" itemtype="http://schema.org/Organization">
          <h3 class="resume-item-title" itemprop="name">Pohang University of Science and Technology</h3>
          <h4 class="resume-item-details" itemprop="description">Researcher &bull; 2016 &mdash; 2014</h4>
          <p class="resume-item-copy">Research involving with computer vision, machine learning and surveillance.</p><br>
          <!--ul class="resume-item-list"-->
            
            <h4 class="resume-item-details" itemprop="description">Moving object detection in a non-stationary camera </h4>
            <p class="resume-item-copy"><strong> [Researcher] </strong> Developed a moving object detection on a non-stationary camera using grid-based background subtraction. Algorithm involves motion compensation of the background model and subtracting the motion compensated background model with the current image to detect the foreground. Suggested a clue-based background model regulation to decrease the noise detected as foreground and an iterative thresholding methodology to use regions with higher probabilities of being a foreground as anchors to detect foreground. Involved in creating a new dataset for foreground detection on a non-stationary camera. Achieved state-of-the-art in 2016.</p>
            <p class="resume-item-copy"><strong> [Required Skillset] </strong> C++</p>
            <p class="resume-item-copy"><img width="350" height="250" src="images/MOD-background-regulation-result.png" alt="my photo" class="avatar no-print" itemprop="image"> <img width="350" height="250" src="images/MOD-iterative.png" alt="my photo" class="avatar no-print" itemprop="image"> <iframe width="350" height="250" src="https://www.youtube.com/embed/SK6ReAVqjD8?si=b4VbHD-CXWzn6LtP" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe></p><br>
            
            <h4 class="resume-item-details" itemprop="description">Vehicle movement classification (moving/stationary) </h4>
            <p class="resume-item-copy"><strong> [Developer] </strong> Used a vehicle detection algorithm and a moving object detection algorithm to create a vehicle movement classification algorithm. The vehicle movement classification algorithm can classify vehicles into moving, stationary and temporarily parked vehicles.</p>
            <p class="resume-item-copy"><strong> [Required Skillset] </strong> C++</p>
            <p class="resume-item-copy"><img width="350" height="250" src="images/moving_vehicle.png" alt="my photo" class="avatar no-print" itemprop="image"> <img width="350" height="250" src="images/static_vehicle.png" alt="my photo" class="avatar no-print" itemprop="image"> <iframe width="350" height="250" src="https://www.youtube.com/embed/EsojV8YUI3U?si=hO4Ny_FLPnTfafQ1" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe></p><br>
            
            <h4 class="resume-item-details" itemprop="description">Traffic light detection </h4>
            <p class="resume-item-copy"><strong> [Developer] </strong> Used Piotr Dollar's Adaboost toolbox for pedestrian detection to detect traffic lights in Korea. Aggregate Channel Features (ACF) was robust in detecting pedestrian and we thought the same robustness will work on traffic light detection. The toolbox was also used to created a dataset for training.</p>
            <p class="resume-item-copy"><strong> [Required Skillset] </strong> MATLAB</p>
            <p class="resume-item-copy"><iframe width="350" height="250" src="https://www.youtube.com/embed/5_WVztXgb2E?si=qrTN3KjkXYdTPM8o" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe></p><br>
            
            <h4 class="resume-item-details" itemprop="description">Traffic accident prediction </h4>
            <p class="resume-item-copy"><strong> [Developer] </strong> Implemented traffic accident prediction by analyzing optical flow in MATLAB. The original methodology can be found <a href="https://ieeexplore.ieee.org/document/6977240">here</a>. The methodology uses a kernel filter to analyze the direction and magnitude of the optical flow.</p>
            <p class="resume-item-copy"><strong> [Required Skillset] </strong> MATLAB</p>
            <p class="resume-item-copy"><iframe width="350" height="250" src="https://www.youtube.com/embed/MGLh7AI53_I?si=8wiU_vNUvcRUDQpM" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe></p><br>
            
          <!--</ul></h5>-->

          <p class="resume-item-copy">
        </div><!-- end of resume-item -->
        
        <div class="resume-item" itemscope itemprop="worksFor" itemtype="http://schema.org/Organization">
          <h3 class="resume-item-title" itemprop="name">Georgia Institute of Technology</h3>
          <h4 class="resume-item-details" itemprop="description">Research Assistant &bull; 2012  &mdash; 2011</h4>
          <p class="resume-item-copy">Focused on helping children’s diet from low income family through technology at Everyday Computing Lab under Andrea Grimes Parker. Reviewed HCI research paper and brain stormed a webpage prototype to encourage children to critical think about food advertisement.</p><br>
          <!--ul class="resume-item-list"-->
            
          <!--</ul></h5>-->

          <p class="resume-item-copy"><iframe width="350" height="250" src="https://www.youtube.com/embed/Ljgk9UxtTDw?si=tNNchMe0ja8NKbE7" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
        </div><!-- end of resume-item -->
        

      </section>
      <!-- end Experience -->
      


      
      <!-- begin Skills -->
      <section class="content-section">

        <header class="section-header">
          <h2>Teaching Experience</h2>
        </header>

        
        <div class="resume-item" itemscope itemprop="memberOf" itemtype="http://schema.org/Organization">
          <h3 class="resume-item-title" itemprop="name"><a href="https://summer.snu.ac.kr/">Seoul National University - International Summer Program (SNU ISP)</a></h3>
          <h4 class="resume-item-details" itemprop="description">First Steps in Programming a Humanoid AI Robot</h4>
          <h4 class="resume-item-details" itemprop="description">Teaching Assistant (TA) &bull; 2022/2023/2024</h4>
          <p class="resume-item-copy">This hands-on course offers a comprehensive exploration of robotics, computer vision, machine learning, and AI, all presented in a practical and accessible manner. No particular prior knowledge on robotics or programming is required, however, basic Python skills are recommended.</p>
        </div>
        
        <div class="resume-item" itemscope itemprop="memberOf" itemtype="http://schema.org/Organization">
          <h3 class="resume-item-title" itemprop="name">Dalian American International School - Extracurricular</h3>
          <h4 class="resume-item-details" itemprop="description">Introduction to Robotics</h4>
          <h4 class="resume-item-details" itemprop="description">Instructor &bull; 2019 Summer/2019 Winter</h4>
          <p class="resume-item-copy">We used Quattro a mini-walking robot to teach the basics in robotics and reinforcement learning.</p>
        </div>
        

      </section>
      <!-- end Skills -->
      

      
      <!-- begin Papers -->
      <section class="content-section">

        <header class="section-header">
          <h2>Papers and Patents</h2>
        </header>

        
        <div class="resume-item" itemscope itemprop="memberOf" itemtype="http://schema.org/Organization">
          <h3 class="resume-item-title" itemprop="name"><a href="https://patents.google.com/patent/US11151992B2/en">AIBRP0008 Context Aware Interactive Robot (US Patent 16227474)</a></h3>
          <h4 class="resume-item-details" itemprop="description">Run Cui, WonTaek Chung, HyeJun Yu &bull; 2018</h4>
          <p class="resume-item-copy">We propose a indoor navigation robot that traverses the environment to complete inventory checks and aid humans in finding products.</p>
        </div>
        
        <div class="resume-item" itemscope itemprop="memberOf" itemtype="http://schema.org/Organization">
          <h3 class="resume-item-title" itemprop="name"><a href="https://ieeexplore.ieee.org/document/7738024">A Two-Stage Foreground Propagation for Moving Object Detection in a Non-Stationary Camera (AVSS)</a></h3>
          <h4 class="resume-item-details" itemprop="description">WonTaek Chung, YongHyun Kim, Yong-Joong Kim, DaiJin Kim &bull; 2016</h4>
          <p class="resume-item-copy">In this paper, we propose a two-stage foreground propagation that uses clues to adapt to the environment and detect moving objects in a non-stationary camera.</p>
        </div>
        
        <div class="resume-item" itemscope itemprop="memberOf" itemtype="http://schema.org/Organization">
          <h3 class="resume-item-title" itemprop="name"><a href="https://ieeexplore.ieee.org/document/7804775">Fast and Accurate Car Detection in Drone-View (ICCE-Asia)</a></h3>
          <h4 class="resume-item-details" itemprop="description">Jongmin Yoon, InHan Kim, WonTaek Chung, Daijin Kim &bull; 2016</h4>
          <p class="resume-item-copy">We propose a way to detect cars in drone-view fast and accurately. For this purpose we proposes a feature called G-ORF for effective feature description. Also we designed a pose classifier and bin-specific weighted Linear Discriminant Analysis (wLDA) classifier for pose classification.</p>
        </div>
        
        <div class="resume-item" itemscope itemprop="memberOf" itemtype="http://schema.org/Organization">
          <h3 class="resume-item-title" itemprop="name"><a href="https://dl.acm.org/citation.cfm?id=2481338">I am What I Eat. Identity & Critical Thinking in an Online Health Forum For Kids. (CHI)</a></h3>
          <h4 class="resume-item-details" itemprop="description">Andrea Grimes Parker, Ian McClendon, Catherine Grevet, Victoria Ayo, WonTaek Chung, Veda Johnson, Elizabeth D. Mynatt &bull; 2013</h4>
          <p class="resume-item-copy">To explore how technology might help kids develop critical thinking, we created an online forum called TalkBack that encourages children to critically analyze the messaging in food ads.</p>
        </div>
        

      </section>
      <!-- end Papers -->
      





      

      
      <!-- begin Skills -->
      <section class="content-section">

        <header class="section-header">
          <h2>Skills</h2>
        </header>
        
        <div class="resume-item">
          <h4 class="resume-item-details">Programming Experience</h4>
          <p class="resume-item-copy">C++, Python, MATLAB, ROS (Robot Operating System), ROS2, Pytorch, Pybullet, Fusion360, CURA, OpenCV, Dlib.</p>
        </div>
        
        <div class="resume-item">
          <h4 class="resume-item-details">Languages</h4>
          <p class="resume-item-copy">Fluent in Korean and English.</p>
        </div>
        

      </section>
      <!-- end Skills -->
      

      

      




      
      
      <!-- begin Links -->
      <section class="content-section">

        <header class="section-header">
          <h2>Participated Events as an Exhibitor</h2>
        </header>

        <div class="resume-item">
          <ul class="resume-item-list">
            
            <li><a href=https://www.startupticker.ch/en/events/digital-day-2019 itemprop="url">2019 Digital Day in Switzerland, St.Gallen - Exhibitor</a></li>
            
            <li><a href=https://www.daischina.org/ itemprop="url">2019 International Day in Dalian, China - Exhibitor</a></li>
            
            <li><a href=https://b2b.ifa-berlin.com/ itemprop="url">2018 IFA Consumer Electronics Unlimited in Germany - Exhibitor</a></li>
            
            <li><a href=http://www.mlaproductions.com/PaloAlto/ itemprop="url">2018 Palo Alto Festival of Arts in USA - Exhibitor</a></li>
            
            <li><a href=http://www.wkforum.org/WKF/2019/ko/index.php itemprop="url">2017 World Knowledge Forum in South Korea - Exhibitor</a></li>
            
            <li><a href=https://dblp.org/db/conf/avss/avss2016 itemprop="url">2016 IEEE International Conference on Advanced Video and Signal-based Surveillance (AVSS) in USA - Exhibitor</a></li>
            
          </ul>
        </div>

      </section>
      <!-- end Links -->
      

      

      
      <!-- begin Print Social Links -->
      <section class="content-section print-only">

        <header class="section-header">
          <h2>Social Links</h2>
        </header>

        <div class="resume-item">
        <!-- and guess where these are defined? Yup, you guessed it: the _config.yml file -->

<ul>

  <!-- GitHub link -->
  

  <!-- Twitter link -->
  
  <li><strong>Twitter</strong>: http://twitter.com/chung_wally</li>
  

  <!-- Dribbble link -->
  

  <!-- Facebook link -->
  

  <!-- LinkedIn link -->
  
  <li><strong>LinkedIn</strong>: https://www.linkedin.com/in/wally-wontaek-chung-60903aa2/</li>
  

  <!-- Instagram link -->
  

  <!-- Website link -->
  

</ul>


        </div>

      </section>
      <!-- end Print Social Links -->
      

      <footer class="page-footer">
        <p class="footer-line"></p>
        <p class="footer-line"></p>
      </footer>

    </div>

  </body>

</html>
