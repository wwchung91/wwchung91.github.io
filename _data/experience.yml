# Jobs
# VP of Global Communications
- company: AIBrain Asia & Crosscert, Republic of Korea
  position: Product Manager/Software Engineer
  duration: 2025 &mdash; 2017
  summary: Managed and contributed to the development of robotics products integrating computer vision, machine learning, and conversational AI, with a primary focus on building an open-source humanoid research platform under the supervision of <a href="https://scholar.google.com/citations?user=g-ZpvTIAAAAJ&hl=en">Prof. Bernhard Egger</a>.
  projects:
      - name: Gretchen Humanoid Robot Head with a 2D Camera
        summary: <strong> [Developer] </strong> Designed and built an open-source humanoid robot head platform with a 2D camera. I created the hardware framework using 3D printing and ROBOTIS motors, replacing the earlier sensorimotor system to improve reliability and reduce costs. In parallel, I developed a ROS-based software framework for motor control, object position estimation in robot coordinates, and remote operation. The platform was specifically designed as an affordable and easy-to-assemble solution for students, and has been adopted in robotics courses at Seoul National University and the Lucerne University of Applied Sciences and Arts.
        skills: <strong> [Required Skillset] </strong> ROS, C++, Python, Fusion360, Cura
        media: <img width="350" height="250" src="images/gretchen-head-2d.png" alt="my photo" class="avatar no-print" itemprop="image"> <img width="350" height="250" src="images/gretchen-2d-architecture.png" alt="my photo" class="avatar no-print" itemprop="image"> <iframe width="350" height="250" src="https://www.youtube.com/embed/9-S6prOuEXU?si=TTUjKCkRzi5tyTqo" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
#You can visit the course website <a href="https://wroboticsai.github.io">here</a>.
      - name: Gretchen Humanoid Robot Head with a 3D Camera
        summary: <strong> [Developer] </strong> Developed the initial Gretchen open-source humanoid robot head platform with a 3D camera. The hardware was originally designed by collaborators at Humboldt-Universität zu Berlin using motors modified with custom sensoriboards, while my role focused on the software stack. I implemented ROS-based modules for motor control, head pose estimation, object detection, and environmental mapping. The system supported AIBrain’s conversational AI by enabling social gaze behaviors, allowing the robot to estimate user gaze direction, build object-centric environment maps, and perform conversational analysis to drive naturalistic head motion and engagement.
        skills: <strong> [Required Skillset] </strong> ROS, C++, Python, Fusion360, Cura
        #Developed both hardware and software. For the hardware, 2D or 3D camera was used with Robotis motors. For the software ROS was used to control the motors and estimate positions of objects in robot coordinates system. The software also includes remote control of the robot head.
        media: <img width="350" height="247" src="images/gretchen-head-3d.png" alt="my photo" class="avatar no-print" itemprop="image"> <img width="350" height="250" src="images/gretchen-head-3d-social-gaze.png" alt="my photo" class="avatar no-print" itemprop="image"> <iframe width="350" height="250" src="https://www.youtube.com/embed/l9jIMoOXDGQ?si=77-xhdG7anlJXjAR" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
        # <img width="410" height="250" src="images/gretchen-head-3d-social-gaze-overall.png" alt="my photo" class="avatar no-print" itemprop="image">

      - name: Gretchen Humanoid AI Online Course
        summary: <strong> [Instructor] </strong> Served as instructor for a nine-week online course built around the Gretchen Humanoid Robot Head (2D Camera). The course provided lectures, guided hands-on exercises, and homework assignments, enabling students to gain practical experience in programming a humanoid robot. Designed for accessibility, the course allowed participants from diverse backgrounds to program a functional robot head, reinforcing the importance of comprehensive and easy-to-follow documentation for open-source platforms.
        skills: <strong> [Required Skillset] </strong> ROS, C++, Python, Moodle
        media: <img width="350" height="250" src="images/gretchen-online-course.png" alt="my photo" class="avatar no-print" itemprop="image"> <img width="350" height="250" src="images/gretchen-online-course-sessions.png" alt="my photo" class="avatar no-print" itemprop="image"> <iframe width="350" height="250" src="https://www.youtube.com/embed/R0SX7h5h7bY?si=ncb9OROu9MF7SpV8" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

      - name: Gretchen Humanoid Robot Leg
        summary: <strong> [Developer] </strong> Led the development of an open-source humanoid robot leg platform for locomotion and balance research. The original design from Humboldt-Universität zu Berlin lacked robustness and key features such as a functional hip joint. I redesigned the hardware with a focus on modularity and replaceable motors to support experimentation, as motors are frequently stressed and replaced in research settings. Through testing, I identified critical limitations in weight distribution and motor performance, concluding that a lighter overall design and further evaluation with alternative motor types are necessary for stable operation.
        skills: <strong> [Required Skillset] </strong> ROS, C++, Python, Fusion360, Cura, Gazebo, Pybullet, Pytorch
        media: <img width="260" height="250" src="images/gretchen-leg-v1.jpg" alt="my photo" class="avatar no-print" itemprop="image"> <iframe width="260" height="250" src="https://www.youtube.com/embed/ssVAxvMDQzs?si=PP_NfbyE9RUp3lbn" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe> <img width="260" height="250" src="images/gretchen-leg-v2.png" alt="my photo" class="avatar no-print" itemprop="image"> <iframe width="260" height="250" src="https://www.youtube.com/embed/UEJbYHxV1Uw?si=_hLpWqZV7eHktPRo" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe> <img width="350" height="250" src="images/leg_diagram.png" alt="my photo" class="avatar no-print" itemprop="image">  <iframe width="350" height="250" src="https://www.youtube.com/embed/xbaOs1Jt5uk?si=8HqqNUEEwT8qiIBw" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

      - name: Biped Robot Simulation/Walking Algorithm Development
        summary: <strong> [Developer] </strong> Explored walking algorithm development for the Gretchen humanoid robot. Due to incomplete hardware, focused on simulation-based approaches, implementing a Deep Deterministic Policy Gradient (DDPG) model to prototype walking behaviors. Work served as groundwork for future integration with ROS, URDF modeling, and hardware testing.
        skills: <strong> [Required Skillset] </strong> ROS, C++, Python, Gazebo, Pybullet, Pytorch
        media:  <iframe width="350" height="250" src="https://www.youtube.com/embed/jMjkOOjizxs?si=5dWX5J0plgbzmr3e" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

#      - name: Soccer Ball Action Spotting - Soccernet CVSports in CVPR 2024
#        summary: <strong> [Developer] </strong> SoccerNet Challenge has various challenges relating to analyzing soccert matches. As a short term project, I worked on ball action spotting. In ball action spotting, given a match video, the algorithm has to classify the frames into {Pass, Drive, Header, High Pass, Out, Cross, Throw In, Shot, Ball Player Block, Player Successful Tackle, Free Kick, Goal}. We extracted 2D features and 3D features with 2D convolution and 3D convolution. With the 3D feature. a transformer encoder layer is used to classify the sequence of videos into an action. Due to the lack of data and time, pretrained weights were used on the 2D and 3D features.
#        skills: <strong> [Required Skillset] </strong> Python, Pytorch
#        media:  <iframe width="350" height="250" src="https://www.youtube.com/embed/jMjkOOjizxs?si=5dWX5J0plgbzmr3e" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

      - name: Quattro Mini Robot
        summary: <strong> [Team Member] </strong> Contributed to the development of Quattro, a miniature walking robot designed to explore locomotion and control. Students can design and build robot legs to investigate the mechanical aspects of legged robots, then tune gait parameters to achieve stable walking. My primary contributions focused on implementing a Q-learning–based behavior, enabling the robot to learn a simple policy of stopping when an obstacle is detected. This introduced students to reinforcement learning principles in a hands-on robotics context.
        skills: <strong> [Required Skillset] </strong> Arduino
        media: <iframe width="350" height="250" src="https://www.youtube.com/embed/W1IbPd5jvEI?si=dN5cy4N9QURzCwoC" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe> <img width="350" height="230" src="images/quattro-rl.png" alt="my photo" class="avatar no-print" itemprop="image">  <iframe width="350" height="250" src="https://www.youtube.com/embed/aRbtsG59ipI?si=yrR2KLxNzdAfggS_" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

      - name: Athena Personal Assistant Robot
        summary: <strong> [Project Manager] </strong> Led the design and implementation of Athena, a personal assistant robot integrating SLAM-based navigation and conversational interaction. Developed on a TurtleBot with LiDAR, RGB-D camera, and tablet interface, Athena used Google Cartographer to build maps and plan navigation routes. To enhance localization, AR/QR codes were incorporated, ensuring more reliable movement in indoor environments. The robot supported simple user dialogues, combining navigation with a conversational interface.
        media: <img width="350" height="250" src="images/athena-hardware.png" alt="my photo" class="avatar no-print" itemprop="image">  <img width="350" height="250" src="images/athena-hardware-inside.png" alt="my photo" class="avatar no-print" itemprop="image">  <iframe width="350" height="250" src="https://www.youtube.com/embed/FTnMlzWFFTA?si=mx8NzHdqe7ZqG7K0" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

      - name: Sensoriboard/Sensorimotor
        summary: <strong> [Team Member] </strong> Contributed to the development and integration of Sensoriboard, a customizable servo motor controller aimed at reducing costs while providing flexible motor control for research applications. My primary role was in applying Sensoriboard to robotic platforms, particularly the Gretchen humanoid robot, where I tested and adapted the controller for practical use. Although my direct contributions to hardware design were limited, I focused on validating its functionality in robotics contexts and identifying key challenges such as calibration and movement accuracy.
        media: <img width="350" height="247" src="images/sensorimotor.jpg" alt="my photo" class="avatar no-print" itemprop="image"> <img width="350" height="247" src="images/sensoriboard-cam.png" alt="my photo" class="avatar no-print" itemprop="image">

      #- name: Athena SLAM
      #  summary:
      #  media:

      #- name: Sensoriboard
      #  summary:
      #  media:

# Director of Digital Stratgy
- company: Pohang University of Science and Technology, Republic of Korea
  position: Researcher
  duration:  2017 &mdash; 2014
  summary: Conducted research in computer vision, machine learning, pattern recognition, and visual surveillance, with a primary focus on moving object detection in non-stationary camera environments.
  projects:
    - name: Moving object detection in a non-stationary camera
      summary: <strong> [Researcher] </strong> Developed a novel framework for detecting moving objects under non-stationary cameras using grid-based background subtraction with motion compensation. Proposed a clue-based background regulation method that adaptively updates the background model based on frame differencing and background subtraction, reducing the impact of inaccurate motion compensation and suppressing false detections. Introduced an iterative threshold refinement algorithm that begins with high-confidence foreground pixels as anchors and progressively adapts thresholds across neighboring regions, improving completeness while minimizing noise. In addition, contributed to the creation of a new dataset tailored for foreground detection in non-stationary camera settings. Experimental results demonstrated state-of-the-art performance in 2016, with significantly higher recall while maintaining strong precision compared to existing methods.
      skills: <strong> [Required Skillset] </strong> C++
      media: <img width="350" height="250" src="images/MOD-background-regulation-result.png" alt="my photo" class="avatar no-print" itemprop="image"> <img width="350" height="250" src="images/MOD-iterative.png" alt="my photo" class="avatar no-print" itemprop="image"> <iframe width="350" height="250" src="https://www.youtube.com/embed/SK6ReAVqjD8?si=b4VbHD-CXWzn6LtP" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

    - name: Vehicle movement classification (moving/stationary)
      summary: <strong> [Developer] </strong> Designed and implemented a vehicle movement classification system by combining a vehicle detection algorithm with a moving object detection framework. The system distinguishes between moving, stationary, and temporarily parked vehicles, enabling more accurate scene understanding for traffic analysis and intelligent transportation applications.
      skills: <strong> [Required Skillset] </strong> C++
      media: <img width="350" height="250" src="images/moving_vehicle.png" alt="my photo" class="avatar no-print" itemprop="image"> <img width="350" height="250" src="images/transition_vehicle.png" alt="my photo" class="avatar no-print" itemprop="image"> <iframe width="350" height="250" src="https://www.youtube.com/embed/EsojV8YUI3U?si=hO4Ny_FLPnTfafQ1" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

    - name: Traffic light detection
      summary: <strong> [Developer] </strong> Applied Piotr Dollár’s Adaboost toolbox, originally designed for pedestrian detection, to the task of traffic light detection in Korea. Leveraged the robustness of Aggregate Channel Features (ACF) to achieve reliable detection performance and developed a custom dataset to support training and evaluation.
      skills: <strong> [Required Skillset] </strong> MATLAB
      media: <iframe width="350" height="250" src="https://www.youtube.com/embed/5_WVztXgb2E?si=qrTN3KjkXYdTPM8o" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

    - name: Traffic accident prediction
      summary: <strong> [Developer] </strong> Implemented traffic accident prediction using Motion Interaction Field in MATLAB. The methodology uses a kernel filter to analyze the direction and magnitude of the optical flow. The kernel filter gives the optical flow give wave like properties where different waves colliding will create large magnitudes. The original methodology can be found <a href="https://ieeexplore.ieee.org/document/6977240">here</a>.
      skills: <strong> [Required Skillset] </strong> MATLAB
      media: <iframe width="350" height="250" src="https://www.youtube.com/embed/MGLh7AI53_I?si=8wiU_vNUvcRUDQpM" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

  #<ul class="resume-item-list"><li><strong>Moving object detection in a non-stationary camera </strong> [<a href="https://youtu.be/SK6ReAVqjD8">https://youtu.be/SK6ReAVqjD8</a>] - Developed a moving object detection on a non-stationary camera using grid-based background subtraction. Algorithm involves motion compensation of the background model and subtracting the motion compensated background model with the current image to detect the foreground. Suggested a clue-based background model #regulation to decrease the noise detected as foreground. Involved in creating a new dataset for foreground detection on a non-stationary camera. Achieved state-of-the-art in 2016. </li><li><strong>Traffic light detection</strong> [<a href="https://youtu.be/cy4JFj1KYr8">https://youtu.be/cy4JFj1KYr8</a>] - Used Piotr Dollar's Adaboost toolbox for pedestrian detection to detect traffic lights in Korea. The toolbox was also used to created a dataset for training. </li><li><strong>Traffic #accident prediction</strong> [<a href="https://youtu.be/hhAQ6EDGTDU">https://youtu.be/hhAQ6EDGTDU</a>] - Implemented traffic accident prediction by analyzing optical flow in MATLAB. The original methodology can be found <a href="https://ieeexplore.ieee.org/document/6977240">here</a>. </li></ul>

# Communications Coordinator
- company:  Georgia Institute of Technology, USA
  position: Research Assistant
  duration:   2012  &mdash; 2011
  summary: Focused on supporting children from low-income families in improving dietary habits through technology. Reviewed HCI research literature and contributed to the design of a webpage prototype that encourages children to critically assess food advertising. Participated in brainstorming sessions and assisted in developing interactive elements to make the platform engaging and educational.
  media: <iframe width="350" height="250" src="https://www.youtube.com/embed/Ljgk9UxtTDw?si=tNNchMe0ja8NKbE7" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
# Communications Coordinator
# Communications Coordinator
#- company:  Secho City Hall
#  position: Part Time Worker
#  duration:   2013
#  summary: Took care of day to day needs of the Korean citizens in Seocho at a city hall.


# Communications Coordinator
#- company:  Seoul Food Exhibition
#  position: Translator
#  duration: 2012
#  summary: Translated English/Korean at an international food expo.

# Communications Coordinator
#- company:  KOTRA Korea Trade Center Malaysia
#  position: Market Research Assistant/Intern
#  duration: 2010
#  summary: Acted as an mediator between buyers and sellers. Completed market research on various products and connected industries between Korea and Malaysia.
