# Jobs
# VP of Global Communications
- company: AIBrain Asia & Crosscert
  position: Product Manager/Software Engineer
  duration: Present &mdash; 2016
  summary: Managed and developed robotics products that include computer vision, machine learning, and conversational AI. Mainly focused on creating an open-sourced humanoid platform.
  projects:
      - name: Gretchen Humanoid Robot Head with a 2D Camera
        summary: <strong> [Developer] </strong> Created an open-source robot head research platform with a 2D camera. Developed a hardware framework with 3D printing and ROBOTIS motors. Developed a software framework with ROS to control the motor, estimate the positions of objects in robot coordinates system, and remotely control the robot. The motivation of creating the Gretchen Humanoid Robot Head with a 2D camera was to provide an easy to assemble and affordable solution for students. This Gretchen Humanoid Robot Head was mainly used for SNU's international summer program.
        skills: <strong> [Required Skillset] </strong> ROS, C++, Python, Fusion360, Cura
        media: <img width="350" height="250" src="images/gretchen-head-2d.png" alt="my photo" class="avatar no-print" itemprop="image"> <img width="350" height="250" src="images/gretchen-2d-architecture.png" alt="my photo" class="avatar no-print" itemprop="image"> <iframe width="350" height="250" src="https://www.youtube.com/embed/9-S6prOuEXU?si=TTUjKCkRzi5tyTqo" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

      - name: Gretchen Humanoid Robot Head with a 3D Camera
        summary: <strong> [Developer] </strong> Created an open-source robot head research platform with a 3D camera. Developed a software framework with ROS to control the motor, estimate headpose, detect objects, and estimate the position of the objects in robot coordinates system. The Gretchen Humanoid Robot Head was intended to support AIBrain's conversational AI by implementing social gaze. The robot gathers environmental knowledge by creating a map of the objects in the environment. It estimates the gaze direction of the user and does a simple analysis of the conversation to determine head motion behavior.
        skills: <strong> [Required Skillset] </strong> ROS, C++, Python, Fusion360, Cura
        #Developed both hardware and software. For the hardware, 2D or 3D camera was used with Robotis motors. For the software ROS was used to control the motors and estimate positions of objects in robot coordinates system. The software also includes remote control of the robot head.
        media: <img width="350" height="247" src="images/gretchen-head-3d.png" alt="my photo" class="avatar no-print" itemprop="image"> <img width="350" height="250" src="images/gretchen-head-3d-social-gaze.png" alt="my photo" class="avatar no-print" itemprop="image"> <iframe width="350" height="250" src="https://www.youtube.com/embed/l9jIMoOXDGQ?si=77-xhdG7anlJXjAR" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
        # <img width="410" height="250" src="images/gretchen-head-3d-social-gaze-overall.png" alt="my photo" class="avatar no-print" itemprop="image">

      - name: Gretchen Humanoid AI Online Course
        summary: <strong> [Instructor] </strong> Based on the Gretchen Humanoid Robot Head with a 2D Camera, we created an online course that works as a guide for using the open sourced platform. After the course, students should be able to program a functional robot head.
        skills: <strong> [Required Skillset] </strong> ROS, C++, Python, Moodle
        media: <img width="350" height="250" src="images/gretchen-online-course.png" alt="my photo" class="avatar no-print" itemprop="image"> <img width="350" height="250" src="images/gretchen-online-course-sessions.png" alt="my photo" class="avatar no-print" itemprop="image"> <iframe width="350" height="250" src="https://www.youtube.com/embed/R0SX7h5h7bY?si=ncb9OROu9MF7SpV8" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

      - name: Gretchen Humanoid Robot Leg
        summary: <strong> [Developer] </strong> Working on an open-source robot leg research platform to experiment walking and balancing algorithms. The hardware was initially created by Humboldt-Universität zu Berlin. The hardware itself needed more improvements and iterations. Software development also more substantial effort and resources.
        skills: <strong> [Required Skillset] </strong> ROS, C++, Python, Fusion360, Cura, Gazebo, Pybullet, Pytorch
        media: <img width="260" height="250" src="images/gretchen-leg-v1.jpg" alt="my photo" class="avatar no-print" itemprop="image"> <iframe width="260" height="250" src="https://www.youtube.com/embed/ssVAxvMDQzs?si=PP_NfbyE9RUp3lbn" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe> <img width="260" height="250" src="images/gretchen-leg-v2.png" alt="my photo" class="avatar no-print" itemprop="image"> <iframe width="260" height="250" src="https://www.youtube.com/embed/UEJbYHxV1Uw?si=_hLpWqZV7eHktPRo" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

      - name: Quattro Mini Robot
        summary: <strong> [Team Member] </strong> Quattro is a mini robot that is used to introduce children to robotics. Students have to build legs and adjust the gait pattern to make the robot walk. We also implemented q-learning so that students could teach the robot to stop when there is an obstacle in front of the robot.
        skills: <strong> [Required Skillset] </strong> Arduino
        media: <iframe width="350" height="250" src="https://www.youtube.com/embed/W1IbPd5jvEI?si=dN5cy4N9QURzCwoC" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe> <img width="350" height="250" src="images/quattro-rl.png" alt="my photo" class="avatar no-print" itemprop="image">  <iframe width="350" height="250" src="https://www.youtube.com/embed/aRbtsG59ipI?si=yrR2KLxNzdAfggS_" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

      - name: Athena Personal Assistant Robot
        summary: <strong> [Project Manager] </strong> Managed the development of a SLAM based personal assistant. The turtlebot used lidar and a RGBD camera to map the indoor environment. Then, global and local path was created to determine which route the robot should take to reach the goal position.
        media: <img width="350" height="250" src="images/athena-hardware.png" alt="my photo" class="avatar no-print" itemprop="image">  <img width="350" height="250" src="images/athena-hardware-inside.png" alt="my photo" class="avatar no-print" itemprop="image">  <iframe width="350" height="250" src="https://www.youtube.com/embed/FTnMlzWFFTA?si=mx8NzHdqe7ZqG7K0" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

      - name: Sensoriboard/Sensorimotor
        summary: <strong> [Team Member] </strong> Sensoriboard is a board that is connected to a motor and allows motor control to be customized. The main aim of the sensoriboard is to reduce the cost of servo motors while also making the motors fully customizable. Assuming the sensoriboards were mass produced, the price is reduced significantly. The problem of sensoriboards were that everything had to be developed from scratch making it very hard to use and prone to inaccurate motor movement. Initially, the sensoriboards/sensorimotors were used in the Gretchen robot.
        media: <img width="350" height="247" src="images/sensorimotor.jpg" alt="my photo" class="avatar no-print" itemprop="image"> <img width="350" height="247" src="images/sensoriboard-cam.png" alt="my photo" class="avatar no-print" itemprop="image">

      #- name: Athena SLAM
      #  summary:
      #  media:

      #- name: Sensoriboard
      #  summary:
      #  media:

# Director of Digital Stratgy
- company: Pohang University of Science and Technology
  position: Researcher
  duration:  2016 &mdash; 2014
  summary: Research involving with computer vision, machine learning and surveillance.
  projects:
    - name: Moving object detection in a non-stationary camera
      summary: <strong> [Researcher] </strong> Developed a moving object detection on a non-stationary camera using grid-based background subtraction. Algorithm involves motion compensation of the background model and subtracting the motion compensated background model with the current image to detect the foreground. Suggested a clue-based background model regulation to decrease the noise detected as foreground and an iterative thresholding methodology to use regions with higher probabilities of being a foreground as anchors to detect foreground. Involved in creating a new dataset for foreground detection on a non-stationary camera. Achieved state-of-the-art in 2016.
      skills: <strong> [Required Skillset] </strong> C++
      media: <img width="350" height="250" src="images/MOD-background-regulation-result.png" alt="my photo" class="avatar no-print" itemprop="image"> <img width="350" height="250" src="images/MOD-iterative.png" alt="my photo" class="avatar no-print" itemprop="image"> <iframe width="350" height="250" src="https://www.youtube.com/embed/SK6ReAVqjD8?si=b4VbHD-CXWzn6LtP" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

    - name: Vehicle movement classification (moving/stationary)
      summary: <strong> [Developer] </strong> Used a vehicle detection algorithm and a moving object detection algorithm to create a vehicle movement classification algorithm. The vehicle movement classification algorithm can classify vehicles into moving, stationary and temporarily parked vehicles.
      skills: <strong> [Required Skillset] </strong> C++
      media: <img width="350" height="250" src="images/moving_vehicle.png" alt="my photo" class="avatar no-print" itemprop="image"> <img width="350" height="250" src="images/static_vehicle.png" alt="my photo" class="avatar no-print" itemprop="image"> <iframe width="350" height="250" src="https://www.youtube.com/embed/EsojV8YUI3U?si=hO4Ny_FLPnTfafQ1" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

    - name: Traffic light detection
      summary: <strong> [Developer] </strong> Used Piotr Dollar's Adaboost toolbox for pedestrian detection to detect traffic lights in Korea. Aggregate Channel Features (ACF) was robust in detecting pedestrian and we thought the same robustness will work on traffic light detection. The toolbox was also used to created a dataset for training.
      skills: <strong> [Required Skillset] </strong> MATLAB
      media: <iframe width="350" height="250" src="https://www.youtube.com/embed/5_WVztXgb2E?si=qrTN3KjkXYdTPM8o" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

    - name: Traffic accident prediction
      summary: <strong> [Developer] </strong> Implemented traffic accident prediction by analyzing optical flow in MATLAB. The original methodology can be found <a href="https://ieeexplore.ieee.org/document/6977240">here</a>. The methodology uses a kernel filter to analyze the direction and magnitude of the optical flow.
      skills: <strong> [Required Skillset] </strong> MATLAB
      media: <iframe width="350" height="250" src="https://www.youtube.com/embed/MGLh7AI53_I?si=8wiU_vNUvcRUDQpM" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

  #<ul class="resume-item-list"><li><strong>Moving object detection in a non-stationary camera </strong> [<a href="https://youtu.be/SK6ReAVqjD8">https://youtu.be/SK6ReAVqjD8</a>] - Developed a moving object detection on a non-stationary camera using grid-based background subtraction. Algorithm involves motion compensation of the background model and subtracting the motion compensated background model with the current image to detect the foreground. Suggested a clue-based background model #regulation to decrease the noise detected as foreground. Involved in creating a new dataset for foreground detection on a non-stationary camera. Achieved state-of-the-art in 2016. </li><li><strong>Traffic light detection</strong> [<a href="https://youtu.be/cy4JFj1KYr8">https://youtu.be/cy4JFj1KYr8</a>] - Used Piotr Dollar's Adaboost toolbox for pedestrian detection to detect traffic lights in Korea. The toolbox was also used to created a dataset for training. </li><li><strong>Traffic #accident prediction</strong> [<a href="https://youtu.be/hhAQ6EDGTDU">https://youtu.be/hhAQ6EDGTDU</a>] - Implemented traffic accident prediction by analyzing optical flow in MATLAB. The original methodology can be found <a href="https://ieeexplore.ieee.org/document/6977240">here</a>. </li></ul>

# Communications Coordinator
- company:  Georgia Institute of Technology
  position: Research Assistant
  duration:   2012  &mdash; 2011
  summary: Focused on helping children’s diet from low income family through technology at Everyday Computing Lab under Andrea Grimes Parker. Brain storming a webpage prototype to encourage critical thinking about food advertisement.
  media: <iframe width="350" height="250" src="https://www.youtube.com/embed/Ljgk9UxtTDw?si=tNNchMe0ja8NKbE7" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
# Communications Coordinator
# Communications Coordinator
#- company:  Secho City Hall
#  position: Part Time Worker
#  duration:   2013
#  summary: Took care of day to day needs of the Korean citizens in Seocho at a city hall.


# Communications Coordinator
#- company:  Seoul Food Exhibition
#  position: Translator
#  duration: 2012
#  summary: Translated English/Korean at an international food expo.

# Communications Coordinator
#- company:  KOTRA Korea Trade Center Malaysia
#  position: Market Research Assistant/Intern
#  duration: 2010
#  summary: Acted as an mediator between buyers and sellers. Completed market research on various products and connected industries between Korea and Malaysia.
